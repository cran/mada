%\VignetteIndexEntry{Meta-Analysis of Diagnostic Accuracy with mada}
%\VignetteKeyword{meta-analysis, diagnostic test}

\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage{amsmath,color,amsthm}
\usepackage{url}
\usepackage{hyperref}
%\usepackage{biblatex}

\DeclareMathOperator{\logit}{logit}
\newcommand{\T}{\mathsf{T}}
\newcommand{\sg}{\sigma}


\title{Meta-Analysis of Diagnostic Accuracy with \texttt{mada}}
\author{Philipp Doebler \\
      philipp.doebler@googlemail.com}

\begin{document}

\setkeys{Gin}{width=0.6\textwidth}


\maketitle

\section{Introduction}
While substantial work has been conducted on methods for diagnostic meta-analysis, it has not become a routine procedure yet. One of the reasons for this is certainly the complexity of bivariate approaches, but another reason is that standard software packages for meta-analysis, for example \emph{Comprehensive Meta-Analysis} and \emph{RevMan} (\cite{cma},\cite{revman}), do not include software to fit models appropriate for diagnostic meta-analysis. For the recommended (\cite{leeflang2008systematic}) bivariate approach of Rutter and Gatsonis (\cite{rutter2001hierarchical}) meta-analysts can use Bayesian approaches (for example in WinBUGS (\cite{lunn2000winbugs}) or OpenBUGS (\cite{lunn2009bugs})), the stata module \texttt{metandi} (\cite{harbord2010metandi}), or the SAS macro \texttt{METADAS} (\cite{takwoingi2008metadas}). So currently available software is either relatively complex (WinBUGS/OpenBUGS) or proprietary (stata, SAS).

The open source R-package \texttt{mada} provides some established and some current approaches to diagnostic meta-analysis, as well as functions to produce descriptive statistics and graphics. It is hopefully complete enough to be the only tool needed for a diagnostic meta-analysis. \texttt{mada} has been developed with an R user in mind that has used standard model fitting functions already, and a lot of the output of \texttt{mada} will look familiar to such a user. While this vignette cannot provide an introduction to R, it is hopefully detailed enough to provide a novice R user with enough hints to perform diagnostic meta-analysis along the lines of it. Free introductions to R are available on the homepage of the \href{http://www.r-project.org/}{R project}. We assume that the reader is familiar with central concepts of meta-analysis, like fixed and random effects models (for example \cite{borenstein2009introductionto}) and ideas behind diagnostic accuracy meta-analysis and (S)ROC curves (a starting points could be \cite{sutton2000methods}, \cite{walter2002properties}, \cite{jones2005summary} or \cite{leeflang2008systematic}).

\section{Obtaining \texttt{mada}}
Once R is installed and an internet connection is available, the package can be installed from CRAN on most systems by typing
<<eval=FALSE>>=
install.packages("mada")
@
Development of \texttt{mada} is hosted at \texttt{http://r-forge.r-project.org/projects/mada/}; the most current version is available there\footnote{For example by typing \texttt{install.packages("mada", repos="http://R-Forge.R-project.org")} at an R prompt.}, while only stable versions are available from CRAN. The package can then be loaded:
<<>>=
library(mada)
@

\section{Entering data}
Primary diagnostic studies observe the result of a \emph{gold standard} procedure which defines the presence or absence of a \emph{condition}, and the result of a  \emph{diagnostic test} (typically some kind of low cost procedure, or at least one that is less invasive than the gold standard). Data from such a primary study could be reported in a $2\times2$ table, see Table \ref{2times2}.

\begin{table}[h]\caption{Data from the $i$th study in a $2\times2$ table}\label{2times2}
\begin{center}
\begin{tabular}[tbp]{lcc}\hline
  		&with condition &without condition \\
\hline
Test positive	& $y_i$		& $z_i$ \\
Test negative	& $m_i-y_i$ 	&$n_i-z_i$\\ 
\hline
Total&$m_i$&$n_i$\\ \hline
\end{tabular}
\end{center}
\end{table}

The numbers $y_i$ and $z_i$ are the numbers of true-positives (TP) and false positives (FP), respectively, and $m_i-y_i$ and $n_i-z_i$ are the numbers of false negatives (FN) and true negatives (TN). Often derived measures of diagnostic accuracy are calculated from 2$\times$2 tables. Using the notation in Table \ref{2times2}, one can calculate

\begin{eqnarray}
p_i = \text{sensitivity of $i$th study}  &=& \frac{y_i}{m_i}\\
u_i = \text{false positive rate of $i$th study} &=& \frac{z_i}{n_i}\\
1- u_i = \text{specificity of $i$th study}  &=& \frac{n_i - z_i}{n_i}.
\end{eqnarray}

Basically all functions in the \texttt{mada} package need data from 2$\times$2 tables. One can use R to calculate the table given specificities or sensitivities if the sample size in each group is known (sometimes there is insufficient data to reconstruct the 2$\times$2 table). The above formulae for the sensitivity for example implies that
\[
y_i = m_ip_i.
\]
If a primary study reports a sensitivity of .944 and that there were 142 people with the condition, we can calculate $y$ by
<<>>=
y <- 142 * .944 
y
@
Since this is not an integer, we need to round it to the nearest integer
<<>>=
round(y)
@
Note that \texttt{mada} is a bit paranoid about the input: it demands that the data and the rounded data are identical to prevent some obvious error.  Hence the use of the \texttt{round} function should not be omitted.

Let us now assume that the number of TP, FP, FN and TN is known for each primary study. A good way to organise information in R is to use \emph{data frames}, which can hold different variables. In our case each row of the data frame corresponds to one primary study. As an example we enter the data from six studies from a meta-analysis of the  AUDIT-C (a short screening test for alcohol problems, \cite{kriston2008meta}) into a data frame
<<>>=
AuditC6 <- data.frame(TP = c(47, 126, 19, 36, 130, 84),
                      FN = c(9, 51, 10, 3, 19, 2),
                      FP = c(101, 272, 12, 78, 211, 68),
                      TN = c(738, 1543, 192, 276, 959, 89))
AuditC6
@
Note that many central functions in \texttt{mada} also accept four vectors of frequencies (TP, FN, FP, TN) as input. Nevertheless, it is convenient to store not only the observed frequencies, but also the study names in the same data frame. The following command shows how to do this for our shortened example:
<<>>=
AuditC6$names <- c("Study 1","Study 2","Study 4","Study 4","Study 5","Study 6")
@
The full data set with 14 studies is part of \texttt{mada}; 
let's load the data set and have a look at the last six studies:
<<>>=
data(AuditC)
tail(AuditC)
@
In the following we will use the \texttt{AuditC} data set as a running example.

\subsection{Zero cells}
In the analysis of data in 2$\times$2 tables zero cells often lead to problems or statistical artefacts since certain ratios do not exist. So called \emph{continuity corrections} are added to the observed frequencies; these are small positive numbers. One suggestions in the literature is to use $0.5$ as the continuity correction, which is the default value in \texttt{mada}. All relevant functions in \texttt{mada} allow user specified continuity corrections and the correction can be applied to all studies, or just to those with zero cells.


\section{Descriptive statistics}
Descriptive statistics for a data set include the sensitivity, specificity and false-positive rate of the primary studies and also their positive and negative likelihood ratios ($\mathrm{LR}_+, \mathrm{LR}_-$), and their diagnostic odds ratio (DOR; \cite{glas2003diagnostic}). These are defined as
\[
\\mathrm{LR}_+ = \frac{p}{u} = \frac{\text{sensitivity}}{\text{false positive rate}},
\]
\[
\mathrm{LR}_- = \frac{1-p}{1-u},
\]
and
\[
\mathrm{DOR} = \frac{\mathrm{LR}_+}{\mathrm{LR}_-} = \frac{\mathrm{TP}\cdot\mathrm{TN}}{\mathrm{FN}\cdot\mathrm{FP}}.
\]
All these are easily computed using the \texttt{madad} function, together with their confidence intervals (see \cite{deeks2001systematic} for the formulae used). \texttt{madad} also performs $\chi^2$ tests to assess heterogeneity of sensitivities and specificities, the null hypothesis being in both cases, that all are equal. Finally the correlation of sensitivities and false positive rates is calculated to give a hint whether the cut-off value problem is present. The following output is slightly cropped.
<<eval=FALSE>>=
madad(AuditC)
@
\begin{Soutput}
Descriptive summary of AuditC with 14 primary studies.
Confidence level for all calculations set to 95 %
Using a continuity correction of 0.5 if applicable 

Diagnostic accuracies 
       sens  2.5% 97.5%  spec  2.5% 97.5%
 [1,] 0.833 0.716 0.908 0.879 0.855 0.899
 [2,] 0.711 0.640 0.772 0.850 0.833 0.866
...
[14,] 0.748 0.684 0.802 0.749 0.702 0.792

Test for equality of sensitivities: 
X-squared = 272.3603, df = 13, p-value = <2e-16
Test for equality of specificities: 
X-squared = 2204.8, df = 13, p-value = <2e-16

Diagnostic OR and likelihood ratios 
           DOR   2.5%     97.5%  posLR  2.5%  97.5% negLR  2.5% 97.5%
 [1,]   36.379 17.587    75.251  6.897 5.556  8.561 0.190 0.106 0.339
...
[14,]    8.850  5.949    13.165  2.982 2.448  3.632 0.337 0.264 0.430

Correlation of sensitivities and false positive rates: 
   rho  2.5 % 97.5 % 
 0.677  0.228  0.888 
\end{Soutput}
For the AUDIT-C data, the underlying call to \texttt{prop.test} produces a warning which should not worry us here. The \texttt{madad} function has a range of options with respect to computational details; for example one can compute 80\% confidence intervals:
<<eval=FALSE>>=
madad(AuditC, level = 0.80)
@
Also note that all the output of \texttt{madad} is available for further computations if one assigns the output of \texttt{madad} to an object. For example the false positive rates with their confidence intervals can be extracted  using the \texttt{\$} construct (output cropped):
<<results=hide>>=
AuditC.d <- madad(AuditC)
AuditC.d$fpr
@
\begin{Soutput}
$fpr
 [1] 0.12083333 0.15005507 0.06097561 0.22112676 0.18061486 0.43354430
 [7] 0.20988806 0.52006770 0.28906250 0.17008929 0.23068670 0.19131238
[13] 0.27564103 0.25070822

$fpr.ci
            2.5%     97.5%
 [1,] 0.10050071 0.1446182
...
[14,] 0.20834216 0.2984416
\end{Soutput}
\subsection{Descriptive graphics}
For the AUDIT-C data, the $\chi^2$ tests already suggested heterogeneity of sensitivities and specificities. The corresponding \emph{forest plots} confirm this:
<<eval=FALSE>>=
forest(madad(AuditC), type = "sens")
forest(madad(AuditC), type = "spec")
@
These plots are shown in Figure \ref{forestplots}.
<<echo=FALSE, results = hide>>=
pdf(file = "pairedforest.pdf", width = 12, height = 6)
par(omi = c(0,0,0,0), mai = c(0.9,0.3,0.3,0.3))
plot.new()
par(fig = c(0, 0.5, 0, 1), pty = "s", new = TRUE)
forest(AuditC.d, type = "sens", xlab = "Sensitivity")
par(fig = c(0.5, 1, 0, 1), pty = "s", new = TRUE)
forest(AuditC.d, type = "spec", xlab = "Specificity")
dev.off()
@

\setkeys{Gin}{width=\textwidth}

\begin{figure}
\begin{center}
\includegraphics{pairedforest}
\caption{Paired forest plot for AUDIT-C data}\label{forestplots}
\end{center}
\end{figure}

\setkeys{Gin}{width=0.6\textwidth}


Apart from these univariate graphics \texttt{mada} provides a variety of plots to study the data on ROC space. Note that for exploratory purposes it is often useful to employ color and other features of R's plotting system. Two high level plots are provided by \texttt{mada}: \texttt{crosshair} to produce crosshair plots (\cite{phillips2010cross}), and \texttt{ROCellipse}. The following is an example of a call of \texttt{crosshair} that produces (arbitrarily) colored crosshairs and makes the crosshairs wider with increased sample size; also only a portion of ROC space is plotted.
<<>>=
## calculate weights:
rs <- rowSums(AuditC)
rs <- 4 * rs/max(rs)
crosshair(AuditC, xlim = c(0,0.6), ylim = c(0.4,1), col = 1:14, lwd = rs)
@
Figure \ref{diagplots} displays this plot and the next descriptive plot.
\texttt{ROCellipse} plots confidence regions which describe the uncertainty of the pair of sensitivity and false positive rate. These regions are ellipses on logit ROC space, and by back-transforming them to regular ROC space the (sometimes oddly shaped) regions are produced. By default this function will also plot the point estimates. The following example is a bit contrived, but showcases the flexibility of \texttt{ROCellipse}: here the plotting of the point estimates is suppressed manipulating the \texttt{pch} argument, but then points are added in the next step.
<<>>=
ROCellipse(AuditC, pch = "")
points(fpr(AuditC), sens(AuditC))
@

<<echo=FALSE, results=hide>>=
pdf(file = "diagplots.pdf", width = 12, height = 6)
par(omi = c(0,0,0,0), mai = c(0.9,0.9,0.3,0.3))
plot.new()
par(fig = c(0, 0.5, 0, 1), pty = "s", new = TRUE)
crosshair(AuditC, xlim = c(0,0.6), ylim = c(0.4,1), col = 1:14, lwd = rs)
par(fig = c(0.5, 1, 0, 1), pty = "s", new = TRUE)
ROCellipse(AuditC, pch = "")
points(fpr(AuditC), sens(AuditC))
dev.off()
@

\setkeys{Gin}{width=\textwidth}

\begin{figure}
\begin{center}
\includegraphics{diagplots}
\caption{A ``weighted'' crosshair plot with (arbitrary) coloring and a plot with confidence regions for primary study estimates}\label{diagplots}
\end{center}
\end{figure}

\setkeys{Gin}{width=0.6\textwidth}


\section{Univariate Approaches}
Before the advent of the bivariate approaches by \cite{rutter2001hierarchical} and \cite{reitsma2005bivariate}, some univariate approaches to the meta-analysis of diagnostic accuracy were more popular. Bivariate approaches can only be recommended though, if the sample size is reasonably large; the bivariate model of \cite{reitsma2005bivariate} for example has 5 parameters, which would clearly be too much for a handful of studies. Hence \texttt{mada} provides some univariate methods. Since pooling sensitivities or specificities can be misleading (\cite{gatsonis2006meta}), options for the univariate meta-analysis of these are not provided. \texttt{mada} does provide approaches for the DOR (\cite{glas2003diagnostic}), the positive and negative likelihood ratios, and $\theta$, the accuracy parameter of the proportional hazards model for diagnostic meta-analysis (\cite{boehningphm}). In this vignette we explain the details on the DOR methodology and the methods for $\theta$.

\subsection{Diagnostic odds ratio}
In analogy to the meta-analysis of the odds ratio (OR) methods for the meta-analysis of the DOR can be developed (\cite{glas2003diagnostic}). For the \emph{fixed effects} case a Mantel-Haenszel (MH; see for example \cite{deeks2001systematic}) is provided by \texttt{mada}. The underlying fixed effects model has the form
\[
\mathrm{DOR}_i = \mu + \epsilon_i,
\]
where $\mu$ is true underlying DOR and the $\epsilon_i$ are independent errors with mean 0 and study specific variance. The MH estimator is a weighted average of DORs observed in the primary studies and is robust to the presence of zero cells. It takes the form
\[
\hat \mu = \sum_i \frac{\omega_i^{MH} \mathrm{DOR}_i}{\sum_i \omega_i^{MH}},
\]
where $\omega_i^{MH} = \frac{z_i(m_i - y_i)}{m_i + n_i}$ are the Mantel-Haenszel weights.

One obtains an estimator for a \emph{random effects} model following the approach of DerSimonian and Laird (DSL; \cite{dersimonian1986meta}). Here the underlying model is in terms of the $\log$ DORs. One assumes
\[
\log\mathrm{DOR}_i = \mu + \epsilon_i + \delta_i,
\]
where $\mu$ is the mean of the $\log$ DORs, $\epsilon_i$ and $\delta_i$ are independent with mean 0; the variance $\sigma_i^2$ of $\epsilon_i$ is estimated as
\[
\hat\sigma_i^2 = \frac{1}{y_i} + \frac{1}{m_i - y_i} +\frac{1}{z_i}  + \frac{1}{n_i -z_i}, 
\]
and the variance $\tau^2$ of $\delta_i$ is to be estimated. The DSL estimator then is a weighted estimator, too:
\[
\hat\mu = \sum_i\frac{\omega_i^{DSL} \mathrm{DOR}_i}{\sum_i \omega_i^{DSL}},
\]
where
\[
\omega_i^{DSL} = \frac{1}{\hat\sigma_i^2 + \tau^2}.
\]
The variance $\tau^2$ is estimated by the Cochran $Q$ statistic trick.

The function \texttt{madauni} handles the meta-analysis of the DOR (and the negative and positive likelihood ratios). One can use \texttt{madauni} in the following fashion:
<<>>=
(fit.DOR.DSL <- madauni(AuditC))
(fit.DOR.MH <- madauni(AuditC, method = "MH"))
@
Note that the brackets around \texttt{fit.DOR.DSL <- madauni(AuditC)} are a compact way to print the fits. The \texttt{print} method for \texttt{madauni} objects is not very informative, only the point estimate is returned along with (in the random effects case) an estimate of the $\tau^2$, the variance of the random effects. Note that estimation in the random effects case is performed on log-DOR scale, so that $\tau^2$ of the above DSL fit is substantial. To obtain more information the \texttt{summary} method can be used:
<<>>=
summary(fit.DOR.DSL)
@
In addition to the confidence intervals, Cochran's $Q$ statistic (\cite{cochran1954combination}) can be seen and Higgins $I^2$ (\cite{higgins2003measuring}). Producing a forest plot of the (log-)DOR values together with the summary estimate is straightforward using the  \texttt{forest} method for the  \texttt{madauni} class:
\begin{center}
<<fig=TRUE>>=
forest(fit.DOR.DSL)
@
\end{center}

\subsection{Proportional hazards model approach}
The proportional hazards model approach (PHM; see \cite{boehningphm}) builds on the assumption of a simple form of the ROC curves. The so called \emph{Lehmann model} (\cite{le2006solution}) is assumed. Let $p_i$ and $u_i$ denote the $i$th study's sensitivity and false positive rate  respectively. The relationship of $p_i$ and $u_i$ is then assumed to be
\[
p_i = u_i^{\theta_i}, 
\]
where $\theta_i > 0$ is a diagnostic accuracy parameter. The smaller $\theta$, the larger the area under the ROC curve and thus the more accurate the diagnostic test. For the meta-analysis of $\theta$ the APMLE estimator is implemented in \texttt{mada} for the case of homogeneity (i.e. fixed effects) and heterogeneity (i.e. random effects). Again the standard output of the \texttt{phm} function is rather sparse:
<<>>=
(fit.phm.homo <- phm(AuditC, hetero = FALSE))
(fit.phm.het <- phm(AuditC))
@
The \texttt{summary} method is more informative:
<<>>=
summary(fit.phm.homo)
@
The $\chi^2$ test goodness of fit test rejects the assumption of homogeneity, but the fit of the model for heterogeneity is better:
<<>>=
summary(fit.phm.het)
@
The estimation of $\theta$ results in an SROC curve; plotting this curve together with confidence bands obtained from the confidence interval of $\theta$ in the summary is simple (we also add the original data on ROC space with confidence regions and only plot a portion of ROC space):

\setkeys{Gin}{width=.8\textwidth}

\begin{center}
<<fig = TRUE>>=
plot(fit.phm.het, xlim = c(0,0.6), ylim = c(0.4,1))
ROCellipse(AuditC, add = TRUE)
@
\end{center}
Note that the SROC curve is not extrapolated beyond the range of the original data. 


\section{A bivariate approach}
Typically the sensitivity and specificity of a diagnostic test depend on each other through a cut-off value: as the cut-off is varied to, say, increase the sensitivity, the specificity often decreases. So in a meta-analytic setting one will often observe (negatively) correlated sensitivities and specificities. This observation can (equivalently) also be state as a (positive) correlation of sensitivities and false positive rates. Since these two quantities are interrelated, bivariate approaches to the meta-analysis of diagnostic accuracy have been quite successful (\cite{rutter2001hierarchical}, \cite{van2002advanced}, \cite{reitsma2005bivariate}, \cite{harbord2007unification}, \cite{arends2008bivariate}).

One typically assumes a binomial model conditional on a primary studies true sensitivity and false positive rates, and a bivariate normal model for the logit-transformed pairs of sensitivities and false positive rates. There are two ways to cast the final model: as a non-linear mixed model or as linear mixed model (see for example \cite{arends2008bivariate}). The latter approach is implemented in \texttt{mada}'s \texttt{reitsma} function, so we give some more details. Let $p_i$ and $u_i$ denote the $i$th study's true sensitivity and false positive rate respectively, and let $\hat p_i$ and $\hat u_i$ denote their estimates from the observed frequencies. Then, since a binomial model is assumed conditional on the true $p_i$, the variance of $\logit(\hat p_i)$ can be approximated by
\[
\frac{\hat p_i(1 - \hat p_i)}{m_i},
\]
and the variance of $\logit(\hat u_i)$ is then
\[
\frac{\hat u_i(1 - \hat u_i)}{n_i}.
\]
So on the within study level one assumes, conditional on $p_i$ and $u_i$, that the observed variation is described by these variances and a normal model; let $D_i$ denote a diagonal 2$\times$2 matrix with the two variances on the diagonal. On the study level, one assumes that a global mean
\[
\mu=(\mu_1,\mu_2)^\T 
\]
and covariance matrix 
\[
\Sigma=\left(
\begin{array}{cc}
\sg_1^2   & 		\sg \\
\sg		&  \sg_2^2
\end{array}\right)
\]
describe the heterogeneity of the pairs $(\logit(p_i),\logit(u_i))$. So the model for the $i$th study is then
\[
(\logit(\hat p_i),\logit(\hat u_i))^\T \sim \mathrm{N}(\mu, \Sigma + D_i).
\]
Fitting this model in \texttt{mada} is similar to the other model fitting functions:
<<>>=
(fit.reitsma <- reitsma(AuditC))
@
The \texttt{print} method for \texttt{reitsma} objects has a scarce output. More information is offered by the \texttt{summary} method:
<<>>=
summary(fit.reitsma)
@
Note the sensitivity and false positive rate returned in this summary are just the back-transformed $\mu_1$ and $\mu_2$. One can then proceed to plot the SROC curve of this model. By default the point estimate of the pair of sensitivity and false positive rate is also plotted together with a confidence region. In the following example the SROC curve is plotted a bit thicker using the \texttt{sroclwd} argument, a caption is added to the plot and also the data and a legend. By default the SROC curve is not extrapolated beyond the range of the original data.
\begin{center}
<<fig=TRUE>>=
plot(fit.reitsma, sroclwd = 2,
     main = "SROC curve (bivariate model) for AUDIT-C data")
points(fpr(AuditC), sens(AuditC), pch = 2)
legend("bottomright", c("data", "summary estimate"), pch = c(2,1))
legend("bottomleft", c("SROC", "conf. region"), lwd = c(2,1))
@
\end{center}

\subsection{Using \texttt{mada} to compare SROC curves}
We show how to compare SROC curves. \cite{patrick1994validity} conducted a meta-analysis to (among other things) investigate the efficacy of self administered and interviewer administered questionnaires to detect nicotine use. The data sets \texttt{SAQ} and \texttt{IAQ} are the respective subsets of this data. First one fits bivariate models to the data sets:
<<>>=
data(IAQ)
data(SAQ)
fit.IAQ <- reitsma(IAQ)
fit.SAQ <- reitsma(SAQ)
@
Then one plots the SROC curves of these fits, beginning with the fit of the IAQ and adding the SAQ curve. Note that the \texttt{lty} arguments is used so that the curves can be distinguished.
\begin{center}
<<fig=TRUE>>=
plot(fit.IAQ, xlim = c(0,.5), ylim = c(.5,1),
     main = "Comparison of IAQ and SAQ")
lines(sroc(fit.SAQ), lty = 2)
ROCellipse(fit.SAQ, lty = 2, pch = 2, add = TRUE)
## add orginal data
points(fpr(IAQ), sens(IAQ), cex = .5)
points(fpr(SAQ), sens(SAQ), pch = 2, cex = 0.5)
legend("bottomright", c("IAQ", "SAQ"), pch = 1:2, lty = 1:2)
@
\end{center}
The summary estimates are well separated, though the confidence regions slightly overlap. It would nevertheless be save to conclude that IAQ is a more reliable way to measure smoking than SAQ.

\section{Further development of \texttt{mada}}
In the future \texttt{mada} will provide functions for meta regression of diagnostic accuracy and will support the mixture approach of \cite{holling2011likelihood} to the meta-analysis of $\theta$ as well as the bivariate approach based on the $t_\alpha$ transformation of \cite{doebler2012mixed}.

\bibliography{mada}{}
\bibliographystyle{alpha}

\end{document}
